{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d662ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c22de69-4947-4fea-abfc-ebf7d07308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from moabb.datasets import BNCI2014_001\n",
    "import numpy as np\n",
    "from ComfyNet import ComfyNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a67553f-aa87-41c8-b000-ab19cb5f2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_config(\"MNE_DATA\",\"bciData\")\n",
    "\n",
    "subjects = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "dataset = BNCI2014_001().get_data(subjects=subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "48c18166-dbe4-4734-a432-90c44233f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subjects, dataset):\n",
    "\n",
    "    X_bci = []\n",
    "    y_bci = []\n",
    "\n",
    "    global bci_n_channels, bci_n_samples, bci_sfreq, n_classes_bci, bci_ch_names\n",
    "    \n",
    "    bci_ch_names = dataset[subjects[0]]['0train']['1'].ch_names\n",
    "    bci_n_channels = len(bci_ch_names)\n",
    "    bci_n_samples = dataset[subjects[0]]['0train']['1'].n_times\n",
    "    bci_sfreq = 250\n",
    "\n",
    "    for subject in dataset:\n",
    "        for session in dataset[subject]:\n",
    "            for trial in dataset[subject][session]:\n",
    "                raw = dataset[subject][session][trial]\n",
    "                events, event_id = mne.events_from_annotations(raw, verbose = False)\n",
    "                epochs = mne.Epochs(raw, events, event_id, 2,6, baseline=None, preload=True, verbose = False)\n",
    "                X_bci.append(epochs.pick('eeg').get_data(copy=False))\n",
    "                y_bci.append(epochs.events[:, 2])\n",
    "                \n",
    "\n",
    "    X_bci = np.array(X_bci)\n",
    "    y_bci = np.array(y_bci)\n",
    "\n",
    "    X_bci_reshaped = X_bci.reshape(-1, X_bci.shape[2], X_bci.shape[3])\n",
    "    y_bci_reshaped = y_bci.reshape(-1)\n",
    "\n",
    "    # 2 = binary classification, left and right hand\n",
    "    # 3 = left hand, right hand, feet\n",
    "    # 4 = left hand, right hand, feet, tongue\n",
    "    n_classes_bci = 2\n",
    "\n",
    "    # Binary classification for left and right hand\n",
    "    if(n_classes_bci == 2):\n",
    "        mask = (y_bci_reshaped != 3) & (y_bci_reshaped != 4)\n",
    "    elif(n_classes_bci == 3):\n",
    "        mask = (y_bci_reshaped != 4) # add feet\n",
    "\n",
    "    y_bci_reshaped = y_bci_reshaped[mask]\n",
    "    X_bci_reshaped = X_bci_reshaped[mask]\n",
    "\n",
    "    # Reset labels to 0 and 1 as expected by pytorch\n",
    "    y_bci_reshaped = y_bci_reshaped - 1\n",
    "\n",
    "    return X_bci_reshaped, y_bci_reshaped\n",
    "\n",
    "X_bci_reshaped, y_bci_reshaped = get_data(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ea02ca46-b554-4762-a0a0-48d48a3a6e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Chebyshev I bandpass non-linear phase (one-pass forward) causal filter:\n",
      "- Filter order 6 (forward)\n",
      "- Cutoffs at 4.00, 40.00 Hz: -1.00, -1.00 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 9200 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 49568 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 50688 out of 50688 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "iir_params = dict(order=3, ftype=\"cheby1\", rp=1, output=\"sos\")\n",
    "low_cut_hz = 4.0\n",
    "high_cut_hz = 40.0\n",
    "\n",
    "# Apply band-pass filter\n",
    "X_bci_reshaped = mne.filter.filter_data(\n",
    "    data=X_bci_reshaped,\n",
    "    method=\"iir\",\n",
    "    iir_params=iir_params,\n",
    "    sfreq=bci_sfreq,\n",
    "    l_freq=low_cut_hz,\n",
    "    h_freq=high_cut_hz,\n",
    "    phase=\"forward\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Apply z-score normalization on X\n",
    "X_mean, X_std =  np.mean(X_bci_reshaped, axis=0),  np.std(X_bci_reshaped, axis=0)\n",
    "X_reshaped = (X_bci_reshaped - X_mean) / X_std\n",
    "\n",
    "# Split data for training and validation\\\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_bci_reshaped, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b5c0476-5f6d-4549-b842-9e217fb0d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWrapped(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, permute = False):\n",
    "        # Convert to torch tensors\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.Y = torch.from_numpy(Y).long()\n",
    "        self.permute = permute\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return(self.X[idx], self.Y[idx])\n",
    "train_dataset_bci = DatasetWrapped(X_train, y_train, permute = True)\n",
    "val_dataset_bci = DatasetWrapped(X_test, y_test, permute = False)\n",
    "\n",
    "from braindecode.augmentation import AugmentedDataLoader, SignFlip, FrequencyShift, ChannelsShuffle\n",
    "sfreq = 250\n",
    "freq_shift = FrequencyShift(\n",
    "    probability=0.5,\n",
    "    sfreq=sfreq,\n",
    "    max_delta_freq=2.0,  # the frequency shifts are sampled now between -2 and 2 Hz\n",
    ")\n",
    "channel_shuffle = ChannelsShuffle(0.5)\n",
    "\n",
    "transforms = [freq_shift]\n",
    "\n",
    "train_dataloader = AugmentedDataLoader(train_dataset_bci, batch_size = 72, transforms = transforms,  shuffle = True)\n",
    "test_dataloader = AugmentedDataLoader(val_dataset_bci, batch_size = 72, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "de6548bf-4be3-4a4b-aeda-3074456131e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "===========================================================================================================================================================\n",
      "ComfyNet (ComfyNet)                                     [1, 22, 1001]             [1, 2]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                [1, 1, 22, 1001]          [1, 60, 16]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                     [1, 1, 22, 1001]          [1, 16, 1, 60]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                             [1, 1, 22, 1001]          [1, 16, 22, 970]          528                       [1, 32]\n",
      "│    │    └─Conv2d (1): 3-2                             [1, 16, 22, 970]          [1, 16, 1, 970]           5,648                     [22, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                        [1, 16, 1, 970]           [1, 16, 1, 970]           32                        --\n",
      "│    │    └─ELU (3): 3-4                                [1, 16, 1, 970]           [1, 16, 1, 970]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                          [1, 16, 1, 970]           [1, 16, 1, 60]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                            [1, 16, 1, 60]            [1, 16, 1, 60]            --                        --\n",
      "│    └─Sequential (projection): 2-2                     [1, 16, 1, 60]            [1, 60, 16]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                             [1, 16, 1, 60]            [1, 16, 1, 60]            272                       [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                          [1, 16, 1, 60]            [1, 60, 16]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                [1, 60, 16]               [1, 60, 16]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                [1, 60, 16]               [1, 60, 16]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                       [1, 60, 16]               [1, 60, 16]               1,120                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                      [1, 60, 16]               [1, 60, 16]               2,160                     --\n",
      "├─_FullyConnected (fc): 1-3                             [1, 60, 16]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-4                             [1, 960]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-11                            [1, 960]                  [1, 256]                  246,016                   --\n",
      "│    │    └─ELU (1): 3-12                               [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-13                           [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-14                            [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-15                               [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-16                           [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                        [1, 32]                   [1, 2]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-5                    [1, 32]                   [1, 2]                    --                        --\n",
      "│    │    └─Linear (0): 3-17                            [1, 32]                   [1, 2]                    66                        --\n",
      "│    │    └─LogSoftmax (classification): 3-18           [1, 2]                    [1, 2]                    --                        --\n",
      "===========================================================================================================================================================\n",
      "Total params: 264,066\n",
      "Trainable params: 264,066\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 17.02\n",
      "===========================================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 3.07\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 4.22\n",
      "===========================================================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Projects\\Serpentine\\comfynet-bci\\base.py:175: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# seed = 20231229\n",
    "\n",
    "# random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = \"cuda\" if cuda else \"cpu\"\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    print(\"Warning: CUDA is not available on this machine, fallback to CPU.\")\n",
    "\n",
    "# Extract number of chans and time steps from dataset\n",
    "n_channels = X_train.shape[1]\n",
    "input_window_samples = X_train.shape[2]\n",
    "\n",
    "model = ComfyNet(\n",
    "    n_outputs=n_classes_bci,\n",
    "    n_chans=len(bci_ch_names[:22]),\n",
    "    n_filters_time=16,\n",
    "    filter_time_length=32,\n",
    "    pool_time_length=75,\n",
    "    pool_time_stride=15,\n",
    "    drop_prob=0.5,\n",
    "    att_depth=1,\n",
    "    att_heads=2,\n",
    "    att_drop_prob=0.5,\n",
    "    return_features=False,\n",
    "    n_times = input_window_samples,\n",
    "    final_fc_length = \"auto\"\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba70d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, optimizer,  loss, train_dataloader, test_dataloader, epochs = 2, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "\n",
    "    pbar = tqdm(range(epochs), colour = 'green')\n",
    "\n",
    "    for epoch in pbar:\n",
    "            \n",
    "        total_train_loss = 0\n",
    "        train_acc = 0\n",
    "        total_val_loss = 0\n",
    "        val_acc = 0\n",
    "        avg_train_loss = 0\n",
    "        avg_val_loss = 0\n",
    "        avg_train_acc=0\n",
    "        avg_val_acc = 0\n",
    "\n",
    "        trained_samples = 0\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for i, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += l.item()\n",
    "            train_acc += (y_pred.argmax(1) == y).sum().item()\n",
    "            trained_samples+= X.shape[0]\n",
    "\n",
    "            avg_train_loss = total_train_loss/len(train_dataloader)\n",
    "            avg_train_acc = train_acc/trained_samples\n",
    "        \n",
    "        validated_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # pbar = tqdm(test_dataloader, colour = 'red')\n",
    "            for X, y in test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_pred = model(X)\n",
    "                l = loss(y_pred, y)\n",
    "                total_val_loss += l.item()\n",
    "                validated_samples += X.shape[0]\n",
    "                val_acc += (y_pred.argmax(1) == y).sum().item()\n",
    "                \n",
    "            avg_val_loss = total_val_loss/len(test_dataloader)\n",
    "            avg_val_acc = val_acc/validated_samples\n",
    "            # print(f\"Validation Loss: {avg_val_loss :.3f}, Validation Accuracy: {avg_val_acc :.3f}\")\n",
    "        pbar.set_description(f\"Epoch {epoch+1}, Loss: {avg_train_loss :.3f}, Train Accuracy: {avg_train_acc :.3f}, Validation Loss: {avg_val_loss :.3f}, Validation Accuracy: {avg_val_acc :.3f}\")\n",
    "\n",
    "\n",
    "    return model, avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc\n",
    "        \n",
    "        # wandb.log({'train_acc':avg_train_acc,\"train_loss\":avg_train_loss, \"val_loss\" : avg_val_loss, \"val_acc\": avg_val_acc})\n",
    "\n",
    "def test(model,loss, test_dataloader, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    total_test_loss = 0\n",
    "    test_samples = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(test_dataloader, colour = 'red')\n",
    "        for i, (X, y) in enumerate(pbar):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            l = loss(y_pred, y)\n",
    "            total_test_loss += l.item()\n",
    "            test_samples += X.shape[0]\n",
    "            test_acc += (y_pred.argmax(1) == y).sum().item()\n",
    "        avg_test_loss = total_test_loss/len(test_dataloader)\n",
    "        avg_test_acc = test_acc/test_samples\n",
    "        print(f\"Test Loss: {avg_test_loss :.3f}, Test Accuracy: {avg_test_acc :.3f}\")\n",
    "        return avg_test_loss, avg_test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7604edb-5cf8-4f83-8b5b-32bc8259891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 200, Loss: 0.280, Train Accuracy: 0.868, Validation Loss: 0.424, Validation Accuracy: 0.805: 100%|\u001b[32m██████████\u001b[0m| 200/200 [03:56<00:00,  1.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ComfyNet(\n",
       "   (patch_embedding): _PatchEmbedding(\n",
       "     (shallownet): Sequential(\n",
       "       (0): Conv2d(1, 16, kernel_size=(1, 32), stride=(1, 1))\n",
       "       (1): Conv2d(16, 16, kernel_size=(22, 1), stride=(1, 1))\n",
       "       (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (3): ELU(alpha=1.0)\n",
       "       (4): AvgPool2d(kernel_size=(1, 75), stride=(1, 15), padding=0)\n",
       "       (5): Dropout(p=0.5, inplace=False)\n",
       "     )\n",
       "     (projection): Sequential(\n",
       "       (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (1): Rearrange('b d_model 1 seq -> b seq d_model')\n",
       "     )\n",
       "   )\n",
       "   (transformer): _TransformerEncoder(\n",
       "     (0): _TransformerEncoderBlock(\n",
       "       (0): _ResidualAdd(\n",
       "         (fn): Sequential(\n",
       "           (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "           (1): _MultiHeadAttention(\n",
       "             (keys): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (queries): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (values): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (att_drop): Dropout(p=0.5, inplace=False)\n",
       "             (projection): Linear(in_features=16, out_features=16, bias=True)\n",
       "           )\n",
       "           (2): Dropout(p=0.5, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): _ResidualAdd(\n",
       "         (fn): Sequential(\n",
       "           (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "           (1): _FeedForwardBlock(\n",
       "             (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "             (1): GELU(approximate='none')\n",
       "             (2): Dropout(p=0.5, inplace=False)\n",
       "             (3): Linear(in_features=64, out_features=16, bias=True)\n",
       "           )\n",
       "           (2): Dropout(p=0.5, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (fc): _FullyConnected(\n",
       "     (fc): Sequential(\n",
       "       (0): Linear(in_features=960, out_features=256, bias=True)\n",
       "       (1): ELU(alpha=1.0)\n",
       "       (2): Dropout(p=0.5, inplace=False)\n",
       "       (3): Linear(in_features=256, out_features=32, bias=True)\n",
       "       (4): ELU(alpha=1.0)\n",
       "       (5): Dropout(p=0.3, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (final_layer): _FinalLayer(\n",
       "     (final_layer): Sequential(\n",
       "       (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "       (classification): LogSoftmax(dim=1)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 0.2802846087463971,\n",
       " 0.8678244090689822,\n",
       " 0.42412081360816956,\n",
       " 0.8051948051948052)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, betas = (0.9,0.999))\n",
    "loss = nn.NLLLoss()\n",
    "train(model, optimizer, loss, train_dataloader, test_dataloader, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0efbaa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 4 - 40 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Chebyshev I bandpass non-linear phase (one-pass forward) causal filter:\n",
      "- Filter order 6 (forward)\n",
      "- Cutoffs at 4.00, 40.00 Hz: -1.00, -1.00 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4332 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 6096 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6336 out of 6336 | elapsed:    0.3s finished\n",
      "100%|\u001b[31m██████████\u001b[0m| 18/18 [00:00<00:00, 124.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.546, Test Accuracy: 0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.5464281506008573, 0.5416666666666666)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 6\n",
    "checkpoint = torch.load(f\"models/model_{i}.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "subjects = [i]\n",
    "dataset = BNCI2014_001().get_data(subjects=subjects)\n",
    "X, y = get_data(subjects, dataset)\n",
    "\n",
    "# Apply band-pass filter\n",
    "X = mne.filter.filter_data(\n",
    "    data=X,\n",
    "    method=\"iir\",\n",
    "    iir_params=iir_params,\n",
    "    sfreq=bci_sfreq,\n",
    "    l_freq=low_cut_hz,\n",
    "    h_freq=high_cut_hz,\n",
    "    phase=\"forward\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "X_norm = (X - X_mean) / X_std\n",
    "test_dataset = DatasetWrapped(X_norm, y, permute = False)\n",
    "test_dataloader = AugmentedDataLoader(test_dataset, batch_size = 16, shuffle = False)\n",
    "test(model, loss, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3c28dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.4, shuffle=True)\n",
    "train_dataset = DatasetWrapped(X_train, y_train, permute = True)\n",
    "val_dataset = DatasetWrapped(X_test, y_test, permute = False)\n",
    "train_dataloader = AugmentedDataLoader(train_dataset, batch_size = 64,  shuffle = True)\n",
    "val_dataloader = AugmentedDataLoader(val_dataset, batch_size = 64, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c8749494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "model2 = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4dfaf315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.377, Train Accuracy: 0.837, Validation Loss: 0.418, Validation Accuracy: 0.853: 100%|\u001b[32m██████████\u001b[0m| 30/30 [00:04<00:00,  7.27it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ComfyNet(\n",
       "   (patch_embedding): _PatchEmbedding(\n",
       "     (shallownet): Sequential(\n",
       "       (0): Conv2d(1, 16, kernel_size=(1, 32), stride=(1, 1))\n",
       "       (1): Conv2d(16, 16, kernel_size=(22, 1), stride=(1, 1))\n",
       "       (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (3): ELU(alpha=1.0)\n",
       "       (4): AvgPool2d(kernel_size=(1, 75), stride=(1, 15), padding=0)\n",
       "       (5): Dropout(p=0.5, inplace=False)\n",
       "     )\n",
       "     (projection): Sequential(\n",
       "       (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "       (1): Rearrange('b d_model 1 seq -> b seq d_model')\n",
       "     )\n",
       "   )\n",
       "   (transformer): _TransformerEncoder(\n",
       "     (0): _TransformerEncoderBlock(\n",
       "       (0): _ResidualAdd(\n",
       "         (fn): Sequential(\n",
       "           (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "           (1): _MultiHeadAttention(\n",
       "             (keys): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (queries): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (values): Linear(in_features=16, out_features=16, bias=True)\n",
       "             (att_drop): Dropout(p=0.5, inplace=False)\n",
       "             (projection): Linear(in_features=16, out_features=16, bias=True)\n",
       "           )\n",
       "           (2): Dropout(p=0.5, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): _ResidualAdd(\n",
       "         (fn): Sequential(\n",
       "           (0): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "           (1): _FeedForwardBlock(\n",
       "             (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "             (1): GELU(approximate='none')\n",
       "             (2): Dropout(p=0.5, inplace=False)\n",
       "             (3): Linear(in_features=64, out_features=16, bias=True)\n",
       "           )\n",
       "           (2): Dropout(p=0.5, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (fc): _FullyConnected(\n",
       "     (fc): Sequential(\n",
       "       (0): Linear(in_features=960, out_features=256, bias=True)\n",
       "       (1): ELU(alpha=1.0)\n",
       "       (2): Dropout(p=0.5, inplace=False)\n",
       "       (3): Linear(in_features=256, out_features=32, bias=True)\n",
       "       (4): ELU(alpha=1.0)\n",
       "       (5): Dropout(p=0.3, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (final_layer): _FinalLayer(\n",
       "     (final_layer): Sequential(\n",
       "       (0): Linear(in_features=32, out_features=2, bias=True)\n",
       "       (classification): LogSoftmax(dim=1)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 0.37705905238787335,\n",
       " 0.8372093023255814,\n",
       " 0.417615607380867,\n",
       " 0.853448275862069)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model2.parameters(), lr=10e-5)\n",
    "loss = nn.NLLLoss()\n",
    "train(model2, optimizer, loss, train_dataloader, val_dataloader, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1be1e372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[31m██████████\u001b[0m| 2/2 [00:00<00:00, 99.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.397, Test Accuracy: 0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.39678336679935455, 0.8362068965517241)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model2, loss, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e0b004c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[31m██████████\u001b[0m| 2/2 [00:00<00:00, 76.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.422, Test Accuracy: 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.422027826309204, 0.5775862068965517)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, loss, val_dataloader)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b3b252a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473ea04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
